rep("green", 50),
rep("blue", 50))
plot(iris.example$Sepal.Length, iris.example$Sepal.Width,
col = col.vec, pch = 16,
main = "Sepal Measurements of Iris Data")
legend("topleft", c("Setosa", "Versicolor", "Virginica"),
pch = 16, col = c("red", "green", "blue"), cex = .75)
set.seed(0)
iris.example$Sepal.Length = jitter(iris.example$Sepal.Length, factor = .5)
iris.example$Sepal.Width = jitter(iris.example$Sepal.Width, factor= .5)
col.vec = c(rep("red", 50), #Creating a color vector for plotting purposes.
rep("green", 50),
rep("blue", 50))
plot(iris.example$Sepal.Length, iris.example$Sepal.Width,
col = col.vec, pch = 16,
main = "Sepal Measurements of Iris Data")
legend("topleft", c("Setosa", "Versicolor", "Virginica"),
pch = 16, col = c("red", "green", "blue"), cex = .75)
plot.new(iris.example$Sepal.Length, iris.example$Sepal.Width,
col = col.vec, pch = 16,
main = "Sepal Measurements of Iris Data")
legend("topleft", c("Setosa", "Versicolor", "Virginica"),
pch = 16, col = c("red", "green", "blue"), cex = .75)
iris
iris.example = iris[, c(1, 2, 5)] #For illustration purposes, pulling only the
#Throwing some small amount of noise on top of the data for illustration
#purposes; some observations are on top of each other.
set.seed(0)
iris.example$Sepal.Length = jitter(iris.example$Sepal.Length, factor = .5)
iris.example$Sepal.Width = jitter(iris.example$Sepal.Width, factor= .5)
col.vec = c(rep("red", 50), #Creating a color vector for plotting purposes.
rep("green", 50),
rep("blue", 50))
plot(iris.example$Sepal.Length, iris.example$Sepal.Width,
col = col.vec, pch = 16,
main = "Sepal Measurements of Iris Data")
legend("topleft", c("Setosa", "Versicolor", "Virginica"),
pch = 16, col = c("red", "green", "blue"), cex = .75)
missing.vector = c(41:50, 91:100, 141:150) #Inducing missing values on the Species
iris.example$Species[missing.vector] = NA  #vector for each category.
iris.example
col.vec[missing.vector] = "purple" #Creating a new color vector to
plot(iris.example$Sepal.Length, iris.example$Sepal.Width,
col = col.vec, pch = 16,
main = "Sepal Measurements of Iris Data")
legend("topleft", c("Setosa", "Versicolor", "Virginica", "NA"),
pch = 16, col = c("red", "green", "blue", "purple"), cex = .75)
#Inspecting the Voronoi tesselation for the complete observations in the iris
#dataset.
library(deldir) #Load the Delaunay triangulation and Dirichelet tesselation library.
info = deldir(iris.example$Sepal.Length[-missing.vector],
iris.example$Sepal.Width[-missing.vector])
plot.tile.list(tile.list(info),
fillcol = col.vec[-missing.vector],
main = "Iris Voronoi Tessellation\nDecision Boundaries")
#Adding the observations that are missing species information.
points(iris.example$Sepal.Length[missing.vector],
iris.example$Sepal.Width[missing.vector],
pch = 16, col = "white")
points(iris.example$Sepal.Length[missing.vector],
iris.example$Sepal.Width[missing.vector],
pch = "?", cex = .66)
#Conducting a 1NN classification imputation.
iris.imputed1NN = kNN(iris.example, k = 1)
#Assessing the results by comparing to the truth known by the original dataset.
table(iris$Species, iris.imputed1NN$Species)
#Mean value imputation method 4.
library(Hmisc) #Load the Harrell miscellaneous library.
#Mean value imputation method 3.
library(caret)
##################################
#####Visualizing Missing Data#####
##################################
library(VIM) #For the visualization and imputation of missing values.
#Conducting a 1NN classification imputation.
iris.imputed1NN = kNN(iris.example, k = 1)
#Assessing the results by comparing to the truth known by the original dataset.
table(iris$Species, iris.imputed1NN$Species)
#Conducting a 12NN classification imputation based on the square root of n.
sqrt(nrow(iris.example))
iris.imputed12NN = kNN(iris.example, k = 12)
#Assessing the results by comparing to the truth known by the original dataset.
table(iris$Species, iris.imputed12NN$Species)
##################################################
#####Using Minkowski Distance Measures in KNN#####
##################################################
library(kknn) #Load the weighted knn library.
#Separating the complete and missing observations for use in the kknn() function.
complete = iris.example[-missing.vector, ]
missing = iris.example[missing.vector, -3]
#Distance corresponds to the Minkowski power. # missing is the data we want to predict on
iris.euclidean = kknn(Species ~ ., complete, missing, k = 12, distance = 2)
summary(iris.euclidean)
summary(cars)
sapply(cars, sd) #Standard deviations.
cor(cars) #Correlations.
#Basic graphical EDA for cars dataset.
hist(cars$speed, xlab = "Speed in MPH", main = "Histogram of Speed")
hist(cars$dist, xlab = "Distance in Feet", main = "Histogram of Distance")
#Manual calculation of simple linear regression coefficients.
beta1 = sum((cars$speed - mean(cars$speed)) * (cars$dist - mean(cars$dist))) /
sum((cars$speed - mean(cars$speed))^2) # Slide 15 of RML_SimpleML
beta0 = mean(cars$dist) - beta1*mean(cars$speed)
#Adding the least squares regression line to the plot.
abline(beta0, beta1, lty = 2)
#Calculating the residual values.
residuals = cars$dist - (beta0 + beta1*cars$speed)
#Note the sum of the residuals is 0.
sum(residuals)
#Visualizing the residuals.
segments(cars$speed, cars$dist,
cars$speed, (beta0 + beta1*cars$speed),
col = "red")
plot(cars, xlab = "Speed in MPH", ylab = "Distance in Feet",
main = "Scatterplot of Cars Dataset")
#Manual calculation of simple linear regression coefficients.
beta1 = sum((cars$speed - mean(cars$speed)) * (cars$dist - mean(cars$dist))) /
sum((cars$speed - mean(cars$speed))^2) # Slide 15 of RML_SimpleML
beta0 = mean(cars$dist) - beta1*mean(cars$speed)
#Adding the least squares regression line to the plot.
abline(beta0, beta1, lty = 2)
#Calculating the residual values.
residuals = cars$dist - (beta0 + beta1*cars$speed)
#Note the sum of the residuals is 0.
sum(residuals)
#Visualizing the residuals.
segments(cars$speed, cars$dist,
cars$speed, (beta0 + beta1*cars$speed),
col = "red")
#Calculating the residual values.
residuals = cars$dist - (beta0 + beta1*cars$speed) # Y - Prediction - Epsilon, Residuals(epsilon) = Y_true - Prediction
#Note the sum of the residuals is 0.
sum(residuals)
#Visualizing the residuals.
segments(cars$speed, cars$dist,
cars$speed, (beta0 + beta1*cars$speed),
col = "red")
text(cars$speed - .5, cars$dist, round(residuals, 2), cex = 0.5)
#################################################
#####Automatic example with the cars dataset#####
#################################################
model = lm(dist ~ speed, data = cars) #Use the linear model function lm() to
summary(model) #All the summary information for the model in question. Reports:
##############################################
#####Manual example with the cars dataset#####
##############################################
help(cars)
cars #Investigating the cars dataset.
#Basic numerical EDA for cars dataset.
summary(cars) #Five number summaries.
sapply(cars, sd) #Standard deviations.
cor(cars) #Correlations.
#Manual calculation of simple linear regression coefficients.
beta1 = sum((cars$speed - mean(cars$speed)) * (cars$dist - mean(cars$dist))) /
sum((cars$speed - mean(cars$speed))^2) # Slide 15 of RML_SimpleML
beta0 = mean(cars$dist) - beta1*mean(cars$speed)
#Adding the least squares regression line to the plot.
abline(beta0, beta1, lty = 2)
library(ggplot2)
#Adding the least squares regression line to the plot.
abline(beta0, beta1, lty = 2)
plot(cars, xlab = "Speed in MPH", ylab = "Distance in Feet",
main = "Scatterplot of Cars Dataset")
#Manual calculation of simple linear regression coefficients.
beta1 = sum((cars$speed - mean(cars$speed)) * (cars$dist - mean(cars$dist))) /
sum((cars$speed - mean(cars$speed))^2) # Slide 15 of RML_SimpleML
beta0 = mean(cars$dist) - beta1*mean(cars$speed)
#Adding the least squares regression line to the plot.
abline(beta0, beta1, lty = 2)
####################################################
#####Checking assumptions with the cars dataset#####
####################################################
#Linearity
plot(cars, xlab = "Speed in MPH", ylab = "Distance in Feet",
main = "Scatterplot of Cars Dataset")
abline(model, lty = 2)
#Constant Variance & Independent Errors
plot(model$fitted, model$residuals,
xlab = "Fitted Values", ylab = "Residual Values",
main = "Residual Plot for Cars Dataset")
#################################################
#####Automatic example with the cars dataset#####
#################################################
model = lm(dist ~ speed, data = cars) #Use the linear model function lm() to
summary(model) #All the summary information for the model in question. Reports:
#Notice that the F-statistic value for the overall regression is the same as the
#square of the t-statistic value for the speed coefficient:
t.statistic = 9.464
f.statistic = 89.57
t.statistic^2
confint(model) #Creating 95% confidence intervals for the model coefficients.
####################################################
#####Checking assumptions with the cars dataset#####
####################################################
#Linearity
plot(cars, xlab = "Speed in MPH", ylab = "Distance in Feet",
main = "Scatterplot of Cars Dataset")
abline(model, lty = 2)
#Constant Variance & Independent Errors
plot(model$fitted, model$residuals,
xlab = "Fitted Values", ylab = "Residual Values",
main = "Residual Plot for Cars Dataset")
#Visualizing another influence plot for the regression model.
library(car) #Companion to applied regression.
influencePlot(model)
#####################################
#####Predicting New Observations#####
#####################################
model$fitted.values #Returns the fitted values.
newdata = data.frame(speed = c(15, 20, 25)) #Creating a new data frame to pass
predict(model, newdata, interval = "confidence") #Construct confidence intervals
predict(model, newdata, interval = "prediction") #Construct prediction invervals
#Constructing confidence and prediction bands for the scope of our data.
newdata = data.frame(speed = 4:25)
conf.band = predict(model, newdata, interval = "confidence")
pred.band = predict(model, newdata, interval = "prediction")
#Visualizing the confidence and prediction bands.
plot(cars, xlab = "Speed in MPH", ylab = "Distance in Feet",
main = "Scatterplot of Cars Dataset")
abline(model, lty = 2) #Plotting the regression line.
lines(newdata$speed, conf.band[, 2], col = "blue") #Plotting the lower confidence band.
lines(newdata$speed, conf.band[, 3], col = "blue") #Plotting the upper confidence band.
lines(newdata$speed, pred.band[, 2], col = "red") #Plotting the lower prediction band.
lines(newdata$speed, pred.band[, 3], col = "red") #Plotting the upper prediction band.
####################################
#####The Box-Cox Transformation#####
####################################
library(car)
bc = boxCox(model) #Automatically plots a 95% confidence interval for the lambda
lambda = bc$x[which(bc$y == max(bc$y))] #Extracting the best lambda value, find the x which gives us the maximum of y
lambda
dist.bc = (cars$dist^lambda - 1)/lambda #Applying the Box-Cox transformation.
model.bc = lm(dist.bc ~ cars$speed) #Creating a new regression based on the
summary(model.bc) #Assessing the output of the new model.
plot(model.bc) #Assessing the assumptions of the new model.
boxCox(model.bc) #What happens if we want to apply the Box-Cox transformation
#####################################################
#####Example using the State Information Dataset#####
#####################################################
help(state.x77)
state.x77 #Investigating the state.x77 dataset.
#Cleaning up the column names so that there are no spaces.
colnames(states)[4] = "Life.Exp"
colnames(states)[6] = "HS.Grad"
states = as.data.frame(state.x77) #Forcing the state.x77 dataset to be a dataframe.
#Cleaning up the column names so that there are no spaces.
colnames(states)[4] = "Life.Exp"
colnames(states)[6] = "HS.Grad"
#Creating a population density variable.
states[,9] = (states$Population*1000)/states$Area # new column with population desnity
colnames(states)[9] = "Density"
#Basic numerical EDA for states dataset.
summary(states)
sapply(states, sd)
cor(states)
# if using simple pure linear regression, no need to normalize.
cor(states)
# if using simple pure linear regression, no need to normalize.
cor(states)
#Basic graphical EDA for the states dataset.
plot(states)
#Creating a saturated model (a model with all variables included).
model.saturated = lm(Life.Exp ~ ., data = states)
summary(model.saturated) #Many predictor variables are not significant, yet the
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message=FALSE)
# Your code here
library(MASS)
cats
ggplot(data = cats, aes(x = cats$Bwt, y = cats$Hwt)) + geom_point(aes(color = cats$Sex)) + labs(title = "Cat Heart Weight vs. Body Weight", x = "Heart Weight", y = "Body Weight")
# Your code here
library(ggplot2)
# Your code here
library(ggplot2)
ggplot(data = cats, aes(x = cats$Bwt, y = cats$Hwt)) + geom_point(aes(color = cats$Sex)) + labs(title = "Cat Heart Weight vs. Body Weight", x = "Heart Weight", y = "Body Weight")
plot(model$fitted, model$residuals,
xlab = "Fitted Values", ylab = "Residual Values",
main = "Residual Plot for Cats Dataset")
# Your code here
# Part A: regression equation
model = lm(Hwt ~ Bwt, data = cats)
summary(model)
plot(cats$Bwt, cats$Hwt, xlab = "Body Weight in kg", ylab = "Heart Weight in g", main = "Scatterplot of Cats Dataset")
abline(a = -0.3567, b = 4.0341, lty = 2)
plot(model$fitted, model$residuals,
xlab = "Fitted Values", ylab = "Residual Values",
main = "Residual Plot for Cats Dataset")
abline(h = 0, lty = 2)
#Normality
qqnorm(model$residuals)
qqline(model$residuals)
qqnorm(model$residuals)
qqline(model$residuals)
plot(cats$Hwt, Hwt.res, main = "Residuals vs. Heart Weight", xlab = "Heart Weight", ylab = "Residuals of Heart Weight")
ggplot(data = cats, aes(x = cats$Bwt, y = cats$Hwt)) + geom_point() + labs(title = "Cat Heart Weight vs. Body Weight", x = "Heart Weight", y = "Body Weight")
Hwt.res = resid(model)
plot(cats$Hwt, Hwt.res, main = "Residuals vs. Heart Weight", xlab = "Heart Weight", ylab = "Residuals of Heart Weight")
abline(0, 0, lty = 5)
# plot the residuals
segments(cats$Bwt,
cats$Hwt,
cats$Bwt,
model$coefficients[1] + model$coefficients[2], col = 'red')
egments(cats$Bwt,
cats$Hwt,
cats$Bwt,
model$coefficients[1] + model$coefficients[2], col = 'red')
segments(cats$Bwt,
cats$Hwt,
cats$Bwt,
model$coefficients[1] + model$coefficients[2], col = 'red')
# Your code here
newdata = data.frame(Bwt = c(2.8, 5, 10))
predict(model, newdata, interval='confidence')
predict(model, newdata, interval='prediction')
Hwt.bc = log(cats$Hwt)
model.bc = lm(Hwt.bc ~ cats$Bwt) # Creating a new regression based on the transformed variable, Hwt.bc
model.bc
shiny::runApp('NYCDSA/Projects/proj2_shiny/wine_enthusiast_reviews/myApp')
runApp('NYCDSA/Projects/proj2_shiny/wine_enthusiast_reviews/myApp')
runApp('NYCDSA/Projects/proj2_shiny/wine_enthusiast_reviews/myApp')
runApp('NYCDSA/Projects/proj2_shiny/wine_enthusiast_reviews/myApp')
runApp('NYCDSA/Projects/proj2_shiny/wine_enthusiast_reviews/myApp')
runApp('NYCDSA/Projects/proj2_shiny/wine_enthusiast_reviews/myApp')
?selectizeInput
runApp('NYCDSA/Projects/proj2_shiny/wine_enthusiast_reviews/myApp')
runApp('NYCDSA/Projects/proj2_shiny/wine_enthusiast_reviews/myApp')
df$variety[df$variety == input$variety1]
df$variety[df$variety == 'merlot']
runApp('NYCDSA/Projects/proj2_shiny/wine_enthusiast_reviews/myApp')
runApp('NYCDSA/Projects/proj2_shiny/wine_enthusiast_reviews/myApp')
runApp('NYCDSA/Projects/proj2_shiny/wine_enthusiast_reviews/myApp')
runApp('NYCDSA/Projects/proj2_shiny/wine_enthusiast_reviews/myApp')
runApp('NYCDSA/Projects/proj2_shiny/wine_enthusiast_reviews/myApp')
runApp('NYCDSA/Projects/proj2_shiny/wine_enthusiast_reviews/myApp')
runApp('NYCDSA/Projects/proj2_shiny/wine_enthusiast_reviews/myApp')
runApp('NYCDSA/Projects/proj2_shiny/wine_enthusiast_reviews/myApp')
runApp('NYCDSA/Projects/proj2_shiny/wine_enthusiast_reviews/myApp')
runApp('NYCDSA/Projects/proj2_shiny/wine_enthusiast_reviews/myApp')
runApp('NYCDSA/Projects/proj2_shiny/wine_enthusiast_reviews/myApp')
runApp('NYCDSA/Projects/proj2_shiny/wine_enthusiast_reviews/myApp')
runApp('NYCDSA/Projects/proj2_shiny/wine_enthusiast_reviews/myApp')
runApp('NYCDSA/Projects/proj2_shiny/wine_enthusiast_reviews/myApp')
df %>% select(everything(), -X.1, -X, -description, -region_2)
runApp('NYCDSA/Projects/proj2_shiny/wine_enthusiast_reviews/myApp')
?return
runApp('NYCDSA/Projects/proj2_shiny/wine_enthusiast_reviews/myApp')
runApp('NYCDSA/Projects/proj2_shiny/wine_enthusiast_reviews/myApp')
?break
?if
runApp('NYCDSA/Projects/proj2_shiny/wine_enthusiast_reviews/myApp')
?observe
runApp('NYCDSA/Projects/proj2_shiny/wine_enthusiast_reviews/myApp')
runApp('NYCDSA/Projects/proj2_shiny/wine_enthusiast_reviews/myApp')
runApp('NYCDSA/Projects/proj2_shiny/wine_enthusiast_reviews/myApp')
runApp('NYCDSA/Projects/proj2_shiny/wine_enthusiast_reviews/myApp')
runApp('NYCDSA/Projects/proj2_shiny/wine_enthusiast_reviews/myApp')
runApp('NYCDSA/Projects/proj2_shiny/wine_enthusiast_reviews/myApp')
shiny::runApp('NYCDSA/Projects/proj2_shiny/wine_enthusiast_reviews/myApp')
df
runApp('NYCDSA/Projects/proj2_shiny/wine_enthusiast_reviews/myApp')
runApp('NYCDSA/Projects/proj2_shiny/wine_enthusiast_reviews/myApp')
runApp('myApp')
runApp('NYCDSA/Projects/proj2_shiny/wine_enthusiast_reviews/myApp')
View(wine_words_filtered)
View(wine_words_filtered)
runApp('NYCDSA/Projects/proj2_shiny/wine_enthusiast_reviews/myApp')
View(wine_words_filtered)
runApp('NYCDSA/Projects/proj2_shiny/wine_enthusiast_reviews/myApp')
runApp('NYCDSA/Projects/proj2_shiny/wine_enthusiast_reviews/myApp')
runApp('NYCDSA/Projects/proj2_shiny/wine_enthusiast_reviews/myApp')
runApp('NYCDSA/Projects/proj2_shiny/wine_enthusiast_reviews/myApp')
runApp('NYCDSA/Projects/proj2_shiny/wine_enthusiast_reviews/myApp')
runApp('NYCDSA/Projects/proj2_shiny/wine_enthusiast_reviews/myApp')
shiny::runApp('NYCDSA/Projects/proj2_shiny/wine_enthusiast_reviews/myApp')
library(shiny)
library(shinydashboard)
library(dplyr)
library(plotly)
library(tidyverse)
setwd("~/Desktop/NYCDSA/Classwork/Projects/proj2_shiny/wine_ratings")
df = read.csv("base_df.csv", stringsAsFactors = F)
df = df %>% select(everything(), -X)
wine_words_filtered = read.csv("wine_words_2.csv", stringsAsFactors = F)
wine_words_filtered = wine_words_filtered %>% select(everything(), -X)
temp = df %>% filter(variety == "Pinot Noir", rating == "Excellent")
mean(temp$price)
mean(temp$price) - 2*sd(temp$price)
mean(temp$price) + 2*sd(temp$price)
mean_x = mean(densityplot$x)
densityplot = density(temp$price)
mean_x = mean(densityplot$x)
mean_x
densityplot$y[densityplot$x == mean_x]
mean_y = densityplot$y[, densityplot$x == mean_x]
densityplot
runApp()
max_y = max(densityplot$y)
max_y
densityplot$x[densityplot$y == max_y]
# max_y = densityplot$y[densityplot$x == mean_x]
# max_x = densityplot$x[densityplot$y == max_y]
runApp()
densityplot$x[densityplot$y == max_y]
runApp()
mean(densityplot$x)
View(densityplot)
mean(temp$price)
?density
runApp()
densityplot$x[densityplot$y == max_y]
max_y
temp = df %>% filter(variety == "Pinot Noir", rating == "Excellent", price <= mean(price) + 3*sd(price), price >= mean(price) - 3*sd(price))
densityplot = density(temp$price)
max_y = max(densityplot$y)
max_y
densityplot$x[densityplot$y == max_y]
density = density(temp$price)
rm(density)
densityplot$x[densityplot$y == max(densityplot$y)]
runApp()
mean(temp$price)
mean(densityplot$x)
mean(densityplot$x) + 2*sd(densityplot$x)
mean(temp$price)
mean(temp$price) + 2*sd(temp$price)
densityplot$y[densityplot$x == mean(temp$price)-2*sd(temp$price)]
densityplot
densityplot$y[densityplot$x == 20]
densityplot$x
densityplot$y[densityplot$x == mean(densityplot$x)-2*sd(densityplot$x)]
mean(densityplot$x)-2*sd(densityplot$x)
mean(densityplot$x)+2*sd(densityplot$x)
mean(densityplot$x)+sd(densityplot$x)
runApp()
temp = df %>% filter(variety == "Pinot Noir", rating == "Excellent", price <= mean(price) + 3*sd(price), price >= mean(price) - 3*sd(price))
densityplot = density(temp$price)
max_y = max(densityplot$y)
mean(temp$price)
mean(temp$price) - 2*sd(temp$price)
xlow = mean(temp$price) - 2*sd(temp$price)
round(mean(temp$price) - 2*sd(temp$price), 0)
densityplot$x == round(21.533406, 2)
round(densityplot$x, 2) == 21.53
xlow
xlow = round(mean(temp$price) - 2*sd(temp$price), 0)
xlow
xlow = round(mean(temp$price) - 2*sd(temp$price), 1)
xlow
plot_ly(x = ~densityplot$x, y = ~densityplot$y, type = 'scatter', mode = 'lines', fill = 'tozeroy',
fillcolor = 'rgba(204,235,197,0.7)', line = list(width = 2, color = 'rgba(255, 77, 77, 0.7)'), height = 600)
example = plot_ly(x = ~densityplot$x, y = ~densityplot$y, type = 'scatter', mode = 'lines', fill = 'tozeroy',
fillcolor = 'rgba(204,235,197,0.7)', line = list(width = 2, color = 'rgba(255, 77, 77, 0.7)'), height = 600)
example <- example %>% layout(title = "Highlighting with Rectangles",
shapes = list(
list(type = "rect",
fillcolor = "blue", line = list(color = "blue"), opacity = 0.3,
x0 = 50, x1 = 60, xref = "x",
y0 = 0, y1 = max(densityplot$y), yref = "y")))
example
example <- example %>% layout(title = "Highlighting with Rectangles",
shapes = list(
list(type = "rect",
fillcolor = "blue", line = list(color = "blue"), opacity = 0.3,
x0 = round(mean(temp$price)), x1 = round(mean(temp$price) + 10), xref = "x",
y0 = 0, y1 = max(densityplot$y), yref = "y")))
example
example <- example %>% layout(title = "Highlighting with Rectangles",
shapes = list(
list(type = "rect",
fillcolor = "blue", line = list(color = "blue"), opacity = 0.3,
x0 = round(mean(temp$price)), x1 = round(mean(temp$price) + 30), xref = "x",
y0 = 0, y1 = max(densityplot$y), yref = "y")))
example
rm(xlow)
mean(temp$price)
mean(temp$price) - 2*sd(temp$price)
xlow = round(mean(temp$price) - 2*sd(temp$price), 0)
xhigh = round(mean(temp$price) + 2*sd(temp$price), 0)
xlow
xhigh
example = plot_ly(x = ~densityplot$x, y = ~densityplot$y, type = 'scatter', mode = 'lines', fill = 'tozeroy',
fillcolor = 'rgba(204,235,197,0.7)', line = list(width = 2, color = 'rgba(255, 77, 77, 0.7)'), height = 600)
example <- example %>% layout(title = "Highlighting with Rectangles",
shapes = list(
list(type = "rect",
fillcolor = "blue", line = list(color = "blue"), opacity = 0.3,
x0 = xlow, x1 = xhigh, xref = "x",
y0 = 0, y1 = max(densityplot$y), yref = "y")))
example
runApp()
mean(temp$price)
mean(densityplot$x)
median(densityplot$x)
densityplot$x[densityplot$y == max(densityplot$y)]
max_x = densityplot$x[densityplot$y == max(densityplot$y)]
max_x
xlow = round(max_x - 2*sd(temp$price), 0)
xhigh = round(max_x + 2*sd(temp$price), 0)
xlow
xhigh
xlow = round(max_x - sd(temp$price), 0)
xhigh = round(max_x + sd(temp$price), 0)
xlow
xhigh
runApp()
median(densityplot$x)
runApp()
densityplot$y[densityplot$x == med_x]
med_x = median(densityplot$x)
densityplot$y[densityplot$x == med_x]
median(densityplot$y)
runApp()
